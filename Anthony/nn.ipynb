{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import Linear, Conv2d, MaxPool2d, ReLU\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LeBal_ConvNet(nn.Module):\n",
    "\tdef __init__(self, num_channels, num_features, num_outputs):\n",
    "\t\tsuper(LeBal_ConvNet, self).__init__()\n",
    "\n",
    "\t\tself.conv1 = Conv2d(in_channels=num_channels, out_channels=20, kernel_size=(5, 5))\n",
    "\t\tself.relu1 = ReLU()\n",
    "\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "\t\tself.conv2 = Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
    "\t\tself.relu2 = ReLU()\n",
    "\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "\t\tself.fc1 = Linear(in_features=400, out_features=500)\n",
    "\t\tself.relu3 = ReLU()\n",
    "\n",
    "\t\tself.fc2 = Linear(in_features=500, out_features=25)\n",
    "\n",
    "\t\tself.sent_fc1 = Linear(in_features=num_features, out_features=100)\n",
    "\t\tself.sent_relu1 = ReLU()\n",
    "\t\tself.sent_fc2 = Linear(in_features=100, out_features=50)\n",
    "\t\tself.sent_relu2 = ReLU()\n",
    "\t\tself.sent_fc3 = Linear(in_features=50, out_features=25)\n",
    "\t\tself.sent_relu3 = ReLU()\n",
    "\n",
    "\t\tself.output1 = Linear(in_features=50, out_features=25)\n",
    "\t\tself.output_relu1 = ReLU()\n",
    "\t\tself.output2 = Linear(in_features=25, out_features=num_outputs)\n",
    "\n",
    "\tdef forward(self, img, sent):\n",
    "\t\tx = self.conv1(img)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.maxpool1(x)\n",
    "\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tx = self.maxpool2(x)\n",
    "\t\tx = torch.flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu3(x)\n",
    "\n",
    "\t\tx = self.fc2(x)\n",
    "\n",
    "\t\txs = self.sent_fc1(sent)\n",
    "\t\txs = self.sent_relu1(xs)\n",
    "\t\txs = self.sent_fc2(xs)\n",
    "\t\txs = self.sent_relu2(xs)\n",
    "\t\txs = self.sent_fc3(xs)\n",
    "\t\txs = self.sent_relu3(xs)\n",
    "\n",
    "\t\tjoined = torch.cat((x, xs), dim=1)\n",
    "\n",
    "\t\txo = self.output1(joined)\n",
    "\t\txo = self.output_relu1(xo)\n",
    "\t\treturn self.output2(xo)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4551, 23, 31, 3) (4551, 3) (4551, 7)\n",
      "[[[0.34117647 0.09803922 0.43529412]\n",
      "  [0.37254902 0.10588235 0.45882353]\n",
      "  [0.43921569 0.1254902  0.4745098 ]\n",
      "  ...\n",
      "  [0.43529412 0.12156863 0.48235294]\n",
      "  [0.38823529 0.10980392 0.47058824]\n",
      "  [0.24313725 0.07058824 0.38431373]]\n",
      "\n",
      " [[0.39215686 0.11372549 0.43921569]\n",
      "  [0.41960784 0.11764706 0.48235294]\n",
      "  [0.4745098  0.1372549  0.48235294]\n",
      "  ...\n",
      "  [0.48627451 0.1372549  0.49019608]\n",
      "  [0.4        0.10980392 0.48627451]\n",
      "  [0.31372549 0.09019608 0.42745098]]\n",
      "\n",
      " [[0.38039216 0.10588235 0.44313725]\n",
      "  [0.43921569 0.12156863 0.49411765]\n",
      "  [0.50980392 0.14901961 0.48235294]\n",
      "  ...\n",
      "  [0.47843137 0.13333333 0.49411765]\n",
      "  [0.37647059 0.10196078 0.4627451 ]\n",
      "  [0.31372549 0.09019608 0.41960784]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.73333333 0.25882353 0.41568627]\n",
      "  [0.77254902 0.27843137 0.44705882]\n",
      "  [0.7254902  0.23921569 0.45490196]\n",
      "  ...\n",
      "  [0.85098039 0.31764706 0.41568627]\n",
      "  [0.75294118 0.25490196 0.44705882]\n",
      "  [0.56470588 0.17647059 0.47843137]]\n",
      "\n",
      " [[0.81568627 0.36470588 0.39215686]\n",
      "  [0.88627451 0.41568627 0.43529412]\n",
      "  [0.85490196 0.39607843 0.43529412]\n",
      "  ...\n",
      "  [0.89019608 0.40784314 0.42352941]\n",
      "  [0.84313725 0.36470588 0.42745098]\n",
      "  [0.67843137 0.25098039 0.45490196]]\n",
      "\n",
      " [[0.70196078 0.28627451 0.43529412]\n",
      "  [0.80392157 0.36078431 0.47058824]\n",
      "  [0.77647059 0.35294118 0.46666667]\n",
      "  ...\n",
      "  [0.80784314 0.36078431 0.45490196]\n",
      "  [0.74117647 0.31764706 0.46666667]\n",
      "  [0.70980392 0.2745098  0.45882353]]]\n",
      "[0.056 0.592 0.353]\n",
      "[0.755  0.454  0.0352 0.757  0.     0.236  0.33  ]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"dataset.npz\")\n",
    "x_img = data['x_img'] / 255.\n",
    "x_sentiment = data['x_sent']\n",
    "y = data['y']\n",
    "print(x_img.shape, x_sentiment.shape, y.shape)\n",
    "print(x_img[0])\n",
    "print(x_sentiment[0])\n",
    "print(y[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(4551, 3, 23, 31)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img = np.moveaxis(x_img, -1, 1)\n",
    "x_img.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b, c):\n",
    "    assert len(a) == len(b) == len(c)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p]\n",
    "\n",
    "sh_x_img, sh_x_sent, sh_y = unison_shuffled_copies(x_img, x_sentiment, y)\n",
    "tt_split = 0.9\n",
    "\n",
    "x_img_train, x_sent_train, y_train = sh_x_img[:int(sh_x_img.shape[0] * tt_split)], sh_x_sent[:int(sh_x_sent.shape[0] * tt_split)], sh_y[:int(sh_y.shape[0] * tt_split)]\n",
    "x_img_test, x_sent_test, y_test = sh_x_img[int(sh_x_img.shape[0] * tt_split):], sh_x_sent[int(sh_x_sent.shape[0] * tt_split):], sh_y[int(sh_y.shape[0] * tt_split):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tx_img_train = torch.Tensor(x_img_train)\n",
    "tx_sentiment_train = torch.Tensor(x_sent_train)\n",
    "ty_train = torch.Tensor(y_train)\n",
    "\n",
    "tx_img_test = torch.Tensor(x_img_test)\n",
    "tx_sentiment_test = torch.Tensor(x_sent_test)\n",
    "ty_test = torch.Tensor(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4095, 3, 23, 31]) torch.Size([4095, 3]) torch.Size([4095, 7])\n",
      "torch.Size([456, 3, 23, 31]) torch.Size([456, 3]) torch.Size([456, 7])\n"
     ]
    }
   ],
   "source": [
    "print(tx_img_train.shape, tx_sentiment_train.shape, ty_train.shape)\n",
    "print(tx_img_test.shape, tx_sentiment_test.shape, ty_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(tx_img_train, tx_sentiment_train, ty_train)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "\n",
    "test_dataset = TensorDataset(tx_img_test, tx_sentiment_test, ty_test)\n",
    "test_dataloader = DataLoader(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = LeBal_ConvNet(3, 3, 7).to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (image, sentiment, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(image, sentiment)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(image)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, sentiment, y in dataloader:\n",
    "            pred = model(image, sentiment)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.300130  [    1/ 4095]\n",
      "loss: 0.028181  [  101/ 4095]\n",
      "loss: 0.030573  [  201/ 4095]\n",
      "loss: 0.139067  [  301/ 4095]\n",
      "loss: 0.067394  [  401/ 4095]\n",
      "loss: 0.064598  [  501/ 4095]\n",
      "loss: 0.036743  [  601/ 4095]\n",
      "loss: 0.056417  [  701/ 4095]\n",
      "loss: 0.018677  [  801/ 4095]\n",
      "loss: 0.094284  [  901/ 4095]\n",
      "loss: 0.058457  [ 1001/ 4095]\n",
      "loss: 0.032074  [ 1101/ 4095]\n",
      "loss: 0.037947  [ 1201/ 4095]\n",
      "loss: 0.041506  [ 1301/ 4095]\n",
      "loss: 0.089511  [ 1401/ 4095]\n",
      "loss: 0.066060  [ 1501/ 4095]\n",
      "loss: 0.013697  [ 1601/ 4095]\n",
      "loss: 0.162546  [ 1701/ 4095]\n",
      "loss: 0.041129  [ 1801/ 4095]\n",
      "loss: 0.050229  [ 1901/ 4095]\n",
      "loss: 0.019073  [ 2001/ 4095]\n",
      "loss: 0.127824  [ 2101/ 4095]\n",
      "loss: 0.068418  [ 2201/ 4095]\n",
      "loss: 0.036076  [ 2301/ 4095]\n",
      "loss: 0.023897  [ 2401/ 4095]\n",
      "loss: 0.117299  [ 2501/ 4095]\n",
      "loss: 0.005497  [ 2601/ 4095]\n",
      "loss: 0.105234  [ 2701/ 4095]\n",
      "loss: 0.072570  [ 2801/ 4095]\n",
      "loss: 0.024711  [ 2901/ 4095]\n",
      "loss: 0.066459  [ 3001/ 4095]\n",
      "loss: 0.090960  [ 3101/ 4095]\n",
      "loss: 0.110791  [ 3201/ 4095]\n",
      "loss: 0.083229  [ 3301/ 4095]\n",
      "loss: 0.084773  [ 3401/ 4095]\n",
      "loss: 0.023202  [ 3501/ 4095]\n",
      "loss: 0.013425  [ 3601/ 4095]\n",
      "loss: 0.112269  [ 3701/ 4095]\n",
      "loss: 0.144681  [ 3801/ 4095]\n",
      "loss: 0.105311  [ 3901/ 4095]\n",
      "loss: 0.017352  [ 4001/ 4095]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.027766  [    1/ 4095]\n",
      "loss: 0.019429  [  101/ 4095]\n",
      "loss: 0.025280  [  201/ 4095]\n",
      "loss: 0.114060  [  301/ 4095]\n",
      "loss: 0.044862  [  401/ 4095]\n",
      "loss: 0.075591  [  501/ 4095]\n",
      "loss: 0.046179  [  601/ 4095]\n",
      "loss: 0.062730  [  701/ 4095]\n",
      "loss: 0.017075  [  801/ 4095]\n",
      "loss: 0.080315  [  901/ 4095]\n",
      "loss: 0.046450  [ 1001/ 4095]\n",
      "loss: 0.030269  [ 1101/ 4095]\n",
      "loss: 0.033836  [ 1201/ 4095]\n",
      "loss: 0.031345  [ 1301/ 4095]\n",
      "loss: 0.073459  [ 1401/ 4095]\n",
      "loss: 0.059202  [ 1501/ 4095]\n",
      "loss: 0.011493  [ 1601/ 4095]\n",
      "loss: 0.137423  [ 1701/ 4095]\n",
      "loss: 0.041477  [ 1801/ 4095]\n",
      "loss: 0.042670  [ 1901/ 4095]\n",
      "loss: 0.013927  [ 2001/ 4095]\n",
      "loss: 0.154033  [ 2101/ 4095]\n",
      "loss: 0.071460  [ 2201/ 4095]\n",
      "loss: 0.035589  [ 2301/ 4095]\n",
      "loss: 0.021734  [ 2401/ 4095]\n",
      "loss: 0.118849  [ 2501/ 4095]\n",
      "loss: 0.006445  [ 2601/ 4095]\n",
      "loss: 0.110708  [ 2701/ 4095]\n",
      "loss: 0.073017  [ 2801/ 4095]\n",
      "loss: 0.030793  [ 2901/ 4095]\n",
      "loss: 0.059188  [ 3001/ 4095]\n",
      "loss: 0.052175  [ 3101/ 4095]\n",
      "loss: 0.107552  [ 3201/ 4095]\n",
      "loss: 0.078508  [ 3301/ 4095]\n",
      "loss: 0.081164  [ 3401/ 4095]\n",
      "loss: 0.019314  [ 3501/ 4095]\n",
      "loss: 0.009357  [ 3601/ 4095]\n",
      "loss: 0.077532  [ 3701/ 4095]\n",
      "loss: 0.165410  [ 3801/ 4095]\n",
      "loss: 0.104837  [ 3901/ 4095]\n",
      "loss: 0.015669  [ 4001/ 4095]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.041425  [    1/ 4095]\n",
      "loss: 0.013190  [  101/ 4095]\n",
      "loss: 0.028897  [  201/ 4095]\n",
      "loss: 0.115034  [  301/ 4095]\n",
      "loss: 0.038814  [  401/ 4095]\n",
      "loss: 0.081952  [  501/ 4095]\n",
      "loss: 0.046770  [  601/ 4095]\n",
      "loss: 0.069136  [  701/ 4095]\n",
      "loss: 0.017533  [  801/ 4095]\n",
      "loss: 0.073705  [  901/ 4095]\n",
      "loss: 0.046888  [ 1001/ 4095]\n",
      "loss: 0.032020  [ 1101/ 4095]\n",
      "loss: 0.033446  [ 1201/ 4095]\n",
      "loss: 0.030150  [ 1301/ 4095]\n",
      "loss: 0.072117  [ 1401/ 4095]\n",
      "loss: 0.057942  [ 1501/ 4095]\n",
      "loss: 0.012381  [ 1601/ 4095]\n",
      "loss: 0.131958  [ 1701/ 4095]\n",
      "loss: 0.038516  [ 1801/ 4095]\n",
      "loss: 0.039564  [ 1901/ 4095]\n",
      "loss: 0.012683  [ 2001/ 4095]\n",
      "loss: 0.158861  [ 2101/ 4095]\n",
      "loss: 0.065031  [ 2201/ 4095]\n",
      "loss: 0.036614  [ 2301/ 4095]\n",
      "loss: 0.021924  [ 2401/ 4095]\n",
      "loss: 0.121887  [ 2501/ 4095]\n",
      "loss: 0.006562  [ 2601/ 4095]\n",
      "loss: 0.104860  [ 2701/ 4095]\n",
      "loss: 0.074213  [ 2801/ 4095]\n",
      "loss: 0.030098  [ 2901/ 4095]\n",
      "loss: 0.057629  [ 3001/ 4095]\n",
      "loss: 0.053013  [ 3101/ 4095]\n",
      "loss: 0.103137  [ 3201/ 4095]\n",
      "loss: 0.075464  [ 3301/ 4095]\n",
      "loss: 0.078679  [ 3401/ 4095]\n",
      "loss: 0.019999  [ 3501/ 4095]\n",
      "loss: 0.009393  [ 3601/ 4095]\n",
      "loss: 0.074501  [ 3701/ 4095]\n",
      "loss: 0.169791  [ 3801/ 4095]\n",
      "loss: 0.103931  [ 3901/ 4095]\n",
      "loss: 0.017375  [ 4001/ 4095]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.043189  [    1/ 4095]\n",
      "loss: 0.013070  [  101/ 4095]\n",
      "loss: 0.030175  [  201/ 4095]\n",
      "loss: 0.117343  [  301/ 4095]\n",
      "loss: 0.037976  [  401/ 4095]\n",
      "loss: 0.082047  [  501/ 4095]\n",
      "loss: 0.047736  [  601/ 4095]\n",
      "loss: 0.070233  [  701/ 4095]\n",
      "loss: 0.017694  [  801/ 4095]\n",
      "loss: 0.072719  [  901/ 4095]\n",
      "loss: 0.046592  [ 1001/ 4095]\n",
      "loss: 0.032884  [ 1101/ 4095]\n",
      "loss: 0.032751  [ 1201/ 4095]\n",
      "loss: 0.028249  [ 1301/ 4095]\n",
      "loss: 0.071073  [ 1401/ 4095]\n",
      "loss: 0.057349  [ 1501/ 4095]\n",
      "loss: 0.013055  [ 1601/ 4095]\n",
      "loss: 0.131764  [ 1701/ 4095]\n",
      "loss: 0.037673  [ 1801/ 4095]\n",
      "loss: 0.040149  [ 1901/ 4095]\n",
      "loss: 0.012374  [ 2001/ 4095]\n",
      "loss: 0.166870  [ 2101/ 4095]\n",
      "loss: 0.062144  [ 2201/ 4095]\n",
      "loss: 0.037172  [ 2301/ 4095]\n",
      "loss: 0.021708  [ 2401/ 4095]\n",
      "loss: 0.123636  [ 2501/ 4095]\n",
      "loss: 0.006506  [ 2601/ 4095]\n",
      "loss: 0.100168  [ 2701/ 4095]\n",
      "loss: 0.076643  [ 2801/ 4095]\n",
      "loss: 0.029245  [ 2901/ 4095]\n",
      "loss: 0.057464  [ 3001/ 4095]\n",
      "loss: 0.052131  [ 3101/ 4095]\n",
      "loss: 0.101495  [ 3201/ 4095]\n",
      "loss: 0.072801  [ 3301/ 4095]\n",
      "loss: 0.073556  [ 3401/ 4095]\n",
      "loss: 0.020655  [ 3501/ 4095]\n",
      "loss: 0.009189  [ 3601/ 4095]\n",
      "loss: 0.075508  [ 3701/ 4095]\n",
      "loss: 0.174514  [ 3801/ 4095]\n",
      "loss: 0.103107  [ 3901/ 4095]\n",
      "loss: 0.018204  [ 4001/ 4095]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.045223  [    1/ 4095]\n",
      "loss: 0.012276  [  101/ 4095]\n",
      "loss: 0.029665  [  201/ 4095]\n",
      "loss: 0.120060  [  301/ 4095]\n",
      "loss: 0.037829  [  401/ 4095]\n",
      "loss: 0.083469  [  501/ 4095]\n",
      "loss: 0.048726  [  601/ 4095]\n",
      "loss: 0.070110  [  701/ 4095]\n",
      "loss: 0.017966  [  801/ 4095]\n",
      "loss: 0.074157  [  901/ 4095]\n",
      "loss: 0.047079  [ 1001/ 4095]\n",
      "loss: 0.034155  [ 1101/ 4095]\n",
      "loss: 0.032898  [ 1201/ 4095]\n",
      "loss: 0.027227  [ 1301/ 4095]\n",
      "loss: 0.072653  [ 1401/ 4095]\n",
      "loss: 0.056618  [ 1501/ 4095]\n",
      "loss: 0.013196  [ 1601/ 4095]\n",
      "loss: 0.132197  [ 1701/ 4095]\n",
      "loss: 0.037377  [ 1801/ 4095]\n",
      "loss: 0.040421  [ 1901/ 4095]\n",
      "loss: 0.012434  [ 2001/ 4095]\n",
      "loss: 0.167902  [ 2101/ 4095]\n",
      "loss: 0.061282  [ 2201/ 4095]\n",
      "loss: 0.037312  [ 2301/ 4095]\n",
      "loss: 0.021916  [ 2401/ 4095]\n",
      "loss: 0.124552  [ 2501/ 4095]\n",
      "loss: 0.006417  [ 2601/ 4095]\n",
      "loss: 0.096633  [ 2701/ 4095]\n",
      "loss: 0.074910  [ 2801/ 4095]\n",
      "loss: 0.027931  [ 2901/ 4095]\n",
      "loss: 0.057439  [ 3001/ 4095]\n",
      "loss: 0.051977  [ 3101/ 4095]\n",
      "loss: 0.102202  [ 3201/ 4095]\n",
      "loss: 0.073044  [ 3301/ 4095]\n",
      "loss: 0.071091  [ 3401/ 4095]\n",
      "loss: 0.019555  [ 3501/ 4095]\n",
      "loss: 0.009154  [ 3601/ 4095]\n",
      "loss: 0.074746  [ 3701/ 4095]\n",
      "loss: 0.173275  [ 3801/ 4095]\n",
      "loss: 0.104172  [ 3901/ 4095]\n",
      "loss: 0.017882  [ 4001/ 4095]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.046274  [    1/ 4095]\n",
      "loss: 0.012378  [  101/ 4095]\n",
      "loss: 0.029744  [  201/ 4095]\n",
      "loss: 0.126681  [  301/ 4095]\n",
      "loss: 0.037400  [  401/ 4095]\n",
      "loss: 0.082251  [  501/ 4095]\n",
      "loss: 0.046864  [  601/ 4095]\n",
      "loss: 0.069732  [  701/ 4095]\n",
      "loss: 0.018132  [  801/ 4095]\n",
      "loss: 0.073474  [  901/ 4095]\n",
      "loss: 0.047357  [ 1001/ 4095]\n",
      "loss: 0.034867  [ 1101/ 4095]\n",
      "loss: 0.032516  [ 1201/ 4095]\n",
      "loss: 0.025804  [ 1301/ 4095]\n",
      "loss: 0.072158  [ 1401/ 4095]\n",
      "loss: 0.056378  [ 1501/ 4095]\n",
      "loss: 0.013373  [ 1601/ 4095]\n",
      "loss: 0.130342  [ 1701/ 4095]\n",
      "loss: 0.036269  [ 1801/ 4095]\n",
      "loss: 0.040704  [ 1901/ 4095]\n",
      "loss: 0.012409  [ 2001/ 4095]\n",
      "loss: 0.171343  [ 2101/ 4095]\n",
      "loss: 0.060599  [ 2201/ 4095]\n",
      "loss: 0.037125  [ 2301/ 4095]\n",
      "loss: 0.022424  [ 2401/ 4095]\n",
      "loss: 0.125994  [ 2501/ 4095]\n",
      "loss: 0.006446  [ 2601/ 4095]\n",
      "loss: 0.097247  [ 2701/ 4095]\n",
      "loss: 0.075069  [ 2801/ 4095]\n",
      "loss: 0.028279  [ 2901/ 4095]\n",
      "loss: 0.057136  [ 3001/ 4095]\n",
      "loss: 0.052875  [ 3101/ 4095]\n",
      "loss: 0.102666  [ 3201/ 4095]\n",
      "loss: 0.073981  [ 3301/ 4095]\n",
      "loss: 0.070264  [ 3401/ 4095]\n",
      "loss: 0.018522  [ 3501/ 4095]\n",
      "loss: 0.009324  [ 3601/ 4095]\n",
      "loss: 0.072990  [ 3701/ 4095]\n",
      "loss: 0.173672  [ 3801/ 4095]\n",
      "loss: 0.102588  [ 3901/ 4095]\n",
      "loss: 0.017911  [ 4001/ 4095]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.047013  [    1/ 4095]\n",
      "loss: 0.012424  [  101/ 4095]\n",
      "loss: 0.029272  [  201/ 4095]\n",
      "loss: 0.121329  [  301/ 4095]\n",
      "loss: 0.036854  [  401/ 4095]\n",
      "loss: 0.085734  [  501/ 4095]\n",
      "loss: 0.050754  [  601/ 4095]\n",
      "loss: 0.071156  [  701/ 4095]\n",
      "loss: 0.018539  [  801/ 4095]\n",
      "loss: 0.072762  [  901/ 4095]\n",
      "loss: 0.047485  [ 1001/ 4095]\n",
      "loss: 0.034726  [ 1101/ 4095]\n",
      "loss: 0.032111  [ 1201/ 4095]\n",
      "loss: 0.025112  [ 1301/ 4095]\n",
      "loss: 0.072479  [ 1401/ 4095]\n",
      "loss: 0.055973  [ 1501/ 4095]\n",
      "loss: 0.013550  [ 1601/ 4095]\n",
      "loss: 0.130871  [ 1701/ 4095]\n",
      "loss: 0.035809  [ 1801/ 4095]\n",
      "loss: 0.040288  [ 1901/ 4095]\n",
      "loss: 0.012260  [ 2001/ 4095]\n",
      "loss: 0.175206  [ 2101/ 4095]\n",
      "loss: 0.060089  [ 2201/ 4095]\n",
      "loss: 0.037438  [ 2301/ 4095]\n",
      "loss: 0.023050  [ 2401/ 4095]\n",
      "loss: 0.126156  [ 2501/ 4095]\n",
      "loss: 0.006390  [ 2601/ 4095]\n",
      "loss: 0.097550  [ 2701/ 4095]\n",
      "loss: 0.073908  [ 2801/ 4095]\n",
      "loss: 0.028563  [ 2901/ 4095]\n",
      "loss: 0.056955  [ 3001/ 4095]\n",
      "loss: 0.052700  [ 3101/ 4095]\n",
      "loss: 0.101522  [ 3201/ 4095]\n",
      "loss: 0.073739  [ 3301/ 4095]\n",
      "loss: 0.070710  [ 3401/ 4095]\n",
      "loss: 0.018204  [ 3501/ 4095]\n",
      "loss: 0.009476  [ 3601/ 4095]\n",
      "loss: 0.073258  [ 3701/ 4095]\n",
      "loss: 0.174930  [ 3801/ 4095]\n",
      "loss: 0.101287  [ 3901/ 4095]\n",
      "loss: 0.018014  [ 4001/ 4095]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.046978  [    1/ 4095]\n",
      "loss: 0.012008  [  101/ 4095]\n",
      "loss: 0.029708  [  201/ 4095]\n",
      "loss: 0.122089  [  301/ 4095]\n",
      "loss: 0.036854  [  401/ 4095]\n",
      "loss: 0.085436  [  501/ 4095]\n",
      "loss: 0.049606  [  601/ 4095]\n",
      "loss: 0.070045  [  701/ 4095]\n",
      "loss: 0.018256  [  801/ 4095]\n",
      "loss: 0.072404  [  901/ 4095]\n",
      "loss: 0.045902  [ 1001/ 4095]\n",
      "loss: 0.034001  [ 1101/ 4095]\n",
      "loss: 0.032594  [ 1201/ 4095]\n",
      "loss: 0.025084  [ 1301/ 4095]\n",
      "loss: 0.071753  [ 1401/ 4095]\n",
      "loss: 0.055511  [ 1501/ 4095]\n",
      "loss: 0.013578  [ 1601/ 4095]\n",
      "loss: 0.129380  [ 1701/ 4095]\n",
      "loss: 0.036482  [ 1801/ 4095]\n",
      "loss: 0.039998  [ 1901/ 4095]\n",
      "loss: 0.011738  [ 2001/ 4095]\n",
      "loss: 0.177238  [ 2101/ 4095]\n",
      "loss: 0.059039  [ 2201/ 4095]\n",
      "loss: 0.037301  [ 2301/ 4095]\n",
      "loss: 0.023098  [ 2401/ 4095]\n",
      "loss: 0.126060  [ 2501/ 4095]\n",
      "loss: 0.006647  [ 2601/ 4095]\n",
      "loss: 0.097684  [ 2701/ 4095]\n",
      "loss: 0.073428  [ 2801/ 4095]\n",
      "loss: 0.028295  [ 2901/ 4095]\n",
      "loss: 0.056182  [ 3001/ 4095]\n",
      "loss: 0.054582  [ 3101/ 4095]\n",
      "loss: 0.103662  [ 3201/ 4095]\n",
      "loss: 0.073955  [ 3301/ 4095]\n",
      "loss: 0.071646  [ 3401/ 4095]\n",
      "loss: 0.017879  [ 3501/ 4095]\n",
      "loss: 0.009518  [ 3601/ 4095]\n",
      "loss: 0.073657  [ 3701/ 4095]\n",
      "loss: 0.173971  [ 3801/ 4095]\n",
      "loss: 0.102690  [ 3901/ 4095]\n",
      "loss: 0.018539  [ 4001/ 4095]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.048001  [    1/ 4095]\n",
      "loss: 0.013798  [  101/ 4095]\n",
      "loss: 0.029423  [  201/ 4095]\n",
      "loss: 0.117965  [  301/ 4095]\n",
      "loss: 0.036757  [  401/ 4095]\n",
      "loss: 0.086480  [  501/ 4095]\n",
      "loss: 0.048914  [  601/ 4095]\n",
      "loss: 0.069196  [  701/ 4095]\n",
      "loss: 0.018237  [  801/ 4095]\n",
      "loss: 0.071754  [  901/ 4095]\n",
      "loss: 0.044932  [ 1001/ 4095]\n",
      "loss: 0.033860  [ 1101/ 4095]\n",
      "loss: 0.032599  [ 1201/ 4095]\n",
      "loss: 0.024617  [ 1301/ 4095]\n",
      "loss: 0.071217  [ 1401/ 4095]\n",
      "loss: 0.055486  [ 1501/ 4095]\n",
      "loss: 0.013825  [ 1601/ 4095]\n",
      "loss: 0.126628  [ 1701/ 4095]\n",
      "loss: 0.037234  [ 1801/ 4095]\n",
      "loss: 0.041120  [ 1901/ 4095]\n",
      "loss: 0.011952  [ 2001/ 4095]\n",
      "loss: 0.176018  [ 2101/ 4095]\n",
      "loss: 0.058232  [ 2201/ 4095]\n",
      "loss: 0.037286  [ 2301/ 4095]\n",
      "loss: 0.023505  [ 2401/ 4095]\n",
      "loss: 0.126019  [ 2501/ 4095]\n",
      "loss: 0.006678  [ 2601/ 4095]\n",
      "loss: 0.096889  [ 2701/ 4095]\n",
      "loss: 0.074159  [ 2801/ 4095]\n",
      "loss: 0.029500  [ 2901/ 4095]\n",
      "loss: 0.055988  [ 3001/ 4095]\n",
      "loss: 0.055045  [ 3101/ 4095]\n",
      "loss: 0.104314  [ 3201/ 4095]\n",
      "loss: 0.074260  [ 3301/ 4095]\n",
      "loss: 0.072280  [ 3401/ 4095]\n",
      "loss: 0.017853  [ 3501/ 4095]\n",
      "loss: 0.009565  [ 3601/ 4095]\n",
      "loss: 0.074577  [ 3701/ 4095]\n",
      "loss: 0.173687  [ 3801/ 4095]\n",
      "loss: 0.102634  [ 3901/ 4095]\n",
      "loss: 0.018718  [ 4001/ 4095]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.048134  [    1/ 4095]\n",
      "loss: 0.014349  [  101/ 4095]\n",
      "loss: 0.029768  [  201/ 4095]\n",
      "loss: 0.116478  [  301/ 4095]\n",
      "loss: 0.036588  [  401/ 4095]\n",
      "loss: 0.088482  [  501/ 4095]\n",
      "loss: 0.049457  [  601/ 4095]\n",
      "loss: 0.069571  [  701/ 4095]\n",
      "loss: 0.018423  [  801/ 4095]\n",
      "loss: 0.069570  [  901/ 4095]\n",
      "loss: 0.043375  [ 1001/ 4095]\n",
      "loss: 0.033772  [ 1101/ 4095]\n",
      "loss: 0.032291  [ 1201/ 4095]\n",
      "loss: 0.024840  [ 1301/ 4095]\n",
      "loss: 0.070927  [ 1401/ 4095]\n",
      "loss: 0.055653  [ 1501/ 4095]\n",
      "loss: 0.013802  [ 1601/ 4095]\n",
      "loss: 0.125556  [ 1701/ 4095]\n",
      "loss: 0.037184  [ 1801/ 4095]\n",
      "loss: 0.040788  [ 1901/ 4095]\n",
      "loss: 0.012174  [ 2001/ 4095]\n",
      "loss: 0.179931  [ 2101/ 4095]\n",
      "loss: 0.058798  [ 2201/ 4095]\n",
      "loss: 0.037164  [ 2301/ 4095]\n",
      "loss: 0.023451  [ 2401/ 4095]\n",
      "loss: 0.125496  [ 2501/ 4095]\n",
      "loss: 0.006560  [ 2601/ 4095]\n",
      "loss: 0.095780  [ 2701/ 4095]\n",
      "loss: 0.074331  [ 2801/ 4095]\n",
      "loss: 0.029699  [ 2901/ 4095]\n",
      "loss: 0.054491  [ 3001/ 4095]\n",
      "loss: 0.054499  [ 3101/ 4095]\n",
      "loss: 0.102196  [ 3201/ 4095]\n",
      "loss: 0.074355  [ 3301/ 4095]\n",
      "loss: 0.073673  [ 3401/ 4095]\n",
      "loss: 0.017907  [ 3501/ 4095]\n",
      "loss: 0.009758  [ 3601/ 4095]\n",
      "loss: 0.073554  [ 3701/ 4095]\n",
      "loss: 0.175711  [ 3801/ 4095]\n",
      "loss: 0.104153  [ 3901/ 4095]\n",
      "loss: 0.018988  [ 4001/ 4095]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [[0.586 0.821 0.082 0.101 0.006 0.699 0.638]]\n",
      "Pred: [[0.565 0.622 0.094 0.259 0.121 0.176 0.497]]\n",
      "\n",
      "True: [[0.724 0.517 0.041 0.117 0.072 0.069 0.926]]\n",
      "Pred: [[0.593 0.659 0.106 0.245 0.138 0.18  0.518]]\n",
      "\n",
      "True: [[0.769 0.551 0.293 0.117 0.    0.216 0.897]]\n",
      "Pred: [[0.566 0.682 0.098 0.23  0.177 0.181 0.477]]\n",
      "\n",
      "True: [[0.737 0.217 0.031 0.77  0.    0.115 0.291]]\n",
      "Pred: [[0.566 0.62  0.094 0.261 0.117 0.176 0.501]]\n",
      "\n",
      "True: [[0.612 0.463 0.035 0.743 0.    0.141 0.535]]\n",
      "Pred: [[0.488 0.824 0.124 0.12  0.305 0.217 0.383]]\n",
      "\n",
      "True: [[0.441 0.241 0.041 0.838 0.    0.335 0.399]]\n",
      "Pred: [[0.558 0.737 0.111 0.186 0.228 0.189 0.456]]\n",
      "\n",
      "True: [[0.937 0.632 0.157 0.026 0.    0.111 0.542]]\n",
      "Pred: [[0.571 0.669 0.099 0.239 0.159 0.181 0.491]]\n",
      "\n",
      "True: [[0.5   0.908 0.042 0.017 0.    0.128 0.744]]\n",
      "Pred: [[0.572 0.648 0.097 0.25  0.139 0.179 0.499]]\n",
      "\n",
      "True: [[0.733 0.783 0.039 0.156 0.    0.286 0.634]]\n",
      "Pred: [[0.537 0.773 0.118 0.157 0.26  0.199 0.43 ]]\n",
      "\n",
      "True: [[0.376 0.39  0.047 0.866 0.921 0.081 0.172]]\n",
      "Pred: [[0.417 0.948 0.145 0.034 0.414 0.249 0.304]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample predictions\n",
    "\n",
    "with torch.no_grad():\n",
    "\tcount = 0\n",
    "\tfor image, sentiment, y in test_dataloader:\n",
    "\t\tif count == 10:\n",
    "\t\t\tbreak\n",
    "\t\tcount += 1\n",
    "\t\tprint('True:', np.around(y.numpy(), decimals=3))\n",
    "\t\tprint('Pred:', np.around(model(image, sentiment).numpy(), decimals=3))\n",
    "\t\tprint()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'model_architecture.png'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "\n",
    "iterator = iter(test_dataloader)\n",
    "x1, x2, y = next(iterator)\n",
    "\n",
    "pred = model(x1, x2)\n",
    "\n",
    "torchviz.make_dot(pred.mean(), params=dict(model.named_parameters())).render(\"model_architecture\", format=\"png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch._C.Node' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [13], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mhiddenlayer\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mhl\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mhl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hiddenlayer\\graph.py:143\u001B[0m, in \u001B[0;36mbuild_graph\u001B[1;34m(model, args, input_names, transforms, framework_transforms)\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch_builder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument args must be provided for Pytorch models.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 143\u001B[0m     \u001B[43mimport_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m framework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_builder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hiddenlayer\\pytorch_builder.py:82\u001B[0m, in \u001B[0;36mimport_graph\u001B[1;34m(hl_graph, model, args, input_names, verbose)\u001B[0m\n\u001B[0;32m     80\u001B[0m op \u001B[38;5;241m=\u001B[39m torch_node\u001B[38;5;241m.\u001B[39mkind()\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# Parameters\u001B[39;00m\n\u001B[1;32m---> 82\u001B[0m params \u001B[38;5;241m=\u001B[39m {k: torch_node[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m torch_node\u001B[38;5;241m.\u001B[39mattributeNames()} \n\u001B[0;32m     83\u001B[0m \u001B[38;5;66;03m# Inputs/outputs\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# TODO: inputs = [i.unique() for i in node.inputs()]\u001B[39;00m\n\u001B[0;32m     85\u001B[0m outputs \u001B[38;5;241m=\u001B[39m [o\u001B[38;5;241m.\u001B[39munique() \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m torch_node\u001B[38;5;241m.\u001B[39moutputs()]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hiddenlayer\\pytorch_builder.py:82\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     80\u001B[0m op \u001B[38;5;241m=\u001B[39m torch_node\u001B[38;5;241m.\u001B[39mkind()\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# Parameters\u001B[39;00m\n\u001B[1;32m---> 82\u001B[0m params \u001B[38;5;241m=\u001B[39m {k: \u001B[43mtorch_node\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m torch_node\u001B[38;5;241m.\u001B[39mattributeNames()} \n\u001B[0;32m     83\u001B[0m \u001B[38;5;66;03m# Inputs/outputs\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# TODO: inputs = [i.unique() for i in node.inputs()]\u001B[39;00m\n\u001B[0;32m     85\u001B[0m outputs \u001B[38;5;241m=\u001B[39m [o\u001B[38;5;241m.\u001B[39munique() \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m torch_node\u001B[38;5;241m.\u001B[39moutputs()]\n",
      "\u001B[1;31mTypeError\u001B[0m: 'torch._C.Node' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "hl.build_graph(model, args=(x1, x2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
